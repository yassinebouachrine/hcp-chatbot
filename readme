# ğŸ‡²ğŸ‡¦ HCP Chatbot - Assistant IA pour DonnÃ©es DÃ©mographiques du Maroc

> Chatbot intelligent spÃ©cialisÃ© dans l'analyse et la consultation des donnÃ©es officielles du **Haut-Commissariat au Plan (HCP)** du Maroc. AccÃ¨s instantanÃ© Ã  plus de 140 000 statistiques dÃ©mographiques couvrant 2000+ territoires marocains.

[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://hub.docker.com/r/bouachrineyassine/hcp-chatbot)
[![Flask](https://img.shields.io/badge/Flask-2.3.3-green?logo=flask)](https://flask.palletsprojects.com/)
[![Python](https://img.shields.io/badge/Python-3.9+-yellow?logo=python)](https://python.org)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—_Transformers-Latest-orange)](https://huggingface.co/transformers/)

## ğŸ“Š Ã€ propos du projet

Le **HCP Chatbot** est un assistant conversationnel intelligent dÃ©veloppÃ© pour faciliter l'accÃ¨s aux donnÃ©es dÃ©mographiques officielles du Maroc. Il utilise des techniques avancÃ©es d'IA pour comprendre et rÃ©pondre aux questions sur :

- **Population lÃ©gale et municipale** par rÃ©gion, province, commune
- **Indicateurs dÃ©mographiques** (Ã¢ge, genre, Ã©tat matrimonial)
- **Statistiques socio-Ã©conomiques** (emploi, Ã©ducation, logement)
- **DonnÃ©es des mÃ©nages** et structures familiales
- **RÃ©partition territoriale** dÃ©taillÃ©e du Royaume

### ğŸ¯ FonctionnalitÃ©s principales

- âœ… **Recherche sÃ©mantique avancÃ©e** dans 140 000+ statistiques HCP
- âœ… **Interface web intuitive** avec chat en temps rÃ©el
- âœ… **API REST complÃ¨te** pour intÃ©grations tierces
- âœ… **Support multilingue** (FranÃ§ais/Arabe)
- âœ… **RÃ©ponses contextuelles** basÃ©es sur l'IA
- âœ… **DÃ©ploiement Docker** prÃªt pour production

## ğŸ—ï¸ Architecture et Technologies

### Stack Technique

| Composant | Technologie | Version | Description |
|-----------|-------------|---------|-------------|
| **Backend** | Python | 3.9+ | Logique mÃ©tier et API |
| **Framework Web** | Flask | 2.3.3 | Serveur web et endpoints |
| **ModÃ¨le Base** | DistilGPT2 | Hugging Face | GÃ©nÃ©ration de texte optimisÃ©e |
| **Embeddings** | all-MiniLM-L6-v2 | Sentence-Transformers | Recherche sÃ©mantique rapide |
| **IA/NLP** | Transformers | Latest | Pipeline de traitement |
| **Frontend** | HTML/CSS/JS | - | Interface utilisateur |
| **Base de donnÃ©es** | JSON | - | Stockage des donnÃ©es HCP |
| **Conteneurisation** | Docker | Latest | DÃ©ploiement unifiÃ© |

### Structure du Projet

```
HCP-CHATBOT/
â”œâ”€â”€ ğŸ“ src/                    # Code source principal
â”‚   â”œâ”€â”€ ğŸ chatbot.py          # Logique du chatbot IA
â”‚   â”œâ”€â”€ ğŸ” data_processor.py   # Traitement donnÃ©es HCP
â”‚   â””â”€â”€ ğŸ¤– model_trainer.py    # EntraÃ®nement modÃ¨les
â”œâ”€â”€ ğŸ“ data/                   # DonnÃ©es HCP
â”‚   â”œâ”€â”€ ğŸ“Š indicators.json     # 140K+ statistiques (200MB+)
â”‚   â””â”€â”€ ğŸ“‹ conversation_history.json
â”œâ”€â”€ ğŸ“ models/                 # ModÃ¨les IA prÃ©-entraÃ®nÃ©s
â”‚   â””â”€â”€ ğŸ“ models_hcp/         # ModÃ¨les spÃ©cialisÃ©s HCP
â”œâ”€â”€ ğŸ“ templates/              # Interface web
â”‚   â””â”€â”€ ğŸŒ index.html          # Page principale
â”œâ”€â”€ ğŸ“ static/                 # Ressources statiques
â”‚   â”œâ”€â”€ ğŸ¨ css/               # Styles
â”‚   â”œâ”€â”€ âš¡ js/                # JavaScript
â”‚   â””â”€â”€ ğŸ–¼ï¸ images/            # Images/logos
â”œâ”€â”€ ğŸ³ docker-compose.yml      # Orchestration Docker
â”œâ”€â”€ ğŸ³ Dockerfile             # Image Docker
â”œâ”€â”€ ğŸ”§ config.py              # Configuration systÃ¨me
â”œâ”€â”€ ğŸš€ app.py                 # Application Flask principale
â””â”€â”€ ğŸ“‹ requirements.txt       # DÃ©pendances Python
```

### ğŸ§  Intelligence Artificielle

Le chatbot utilise une architecture hybride optimisÃ©e pour les donnÃ©es HCP :

#### **ModÃ¨le de GÃ©nÃ©ration : DistilGPT2**
- **Avantages** : Version distillÃ©e de GPT-2, plus rapide et lÃ©gÃ¨re
- **Utilisation** : GÃ©nÃ©ration de rÃ©ponses contextuelles fluides
- **Performance** : 82M paramÃ¨tres vs 124M pour GPT-2 standard
- **SpÃ©cialisation** : Fine-tunÃ© sur les donnÃ©es dÃ©mographiques HCP

#### **ModÃ¨le d'Embeddings : all-MiniLM-L6-v2**
- **Architecture** : 22M paramÃ¨tres, trÃ¨s efficace
- **Vitesse** : ~14 000 phrases/seconde sur CPU
- **QualitÃ©** : Score SBERT de 82.05 sur tÃ¢ches sÃ©mantiques
- **Langues** : Support multilingue (FranÃ§ais inclus)

#### **Pipeline de Traitement**
1. **Encodage SÃ©mantique** : Conversion de la question en vecteur 384D
2. **Recherche Vectorielle** : SimilaritÃ© cosinus dans la base HCP
3. **Classification Contextuelle** : DÃ©tection territoire/indicateur/type
4. **GÃ©nÃ©ration GuidÃ©e** : DistilGPT2 avec contexte HCP spÃ©cialisÃ©

#### **Optimisations SpÃ©cifiques HCP**
- **Index Vectoriel** : 140K+ embeddings prÃ©-calculÃ©s et mis en cache
- **Filtrage Intelligent** : Priorisation des donnÃ©es les plus pertinentes
- **Adaptation Terminologique** : Vocabulaire spÃ©cialisÃ© dÃ©mographie Maroc

## ğŸš€ Installation et Utilisation

### Option 1: Docker Hub (RecommandÃ©)

Le moyen le plus simple pour dÃ©marrer :

```bash
# 1. TÃ©lÃ©charger l'image depuis Docker Hub
docker pull bouachrineyassine/hcp-chatbot:latest

# 2. Lancer le chatbot
docker run -d \
  --name hcp-chatbot \
  -p 5000:5000 \
  -e FLASK_ENV=production \
  bouachrineyassine/hcp-chatbot:latest

# 3. AccÃ©der Ã  l'interface
# Ouvrir: http://localhost:5000
```

### Option 2: Docker Compose (DÃ©veloppement)

Pour un contrÃ´le total et des personnalisations :

```bash
# 1. Cloner le repository
git clone https://github.com/yassinebouachrine/hcp-chatbot.git
cd hcp-chatbot

# 2. Configuration (optionnel)
cp .env.template .env
# Ã‰diter .env selon vos besoins

# 3. Construire et lancer
docker-compose up -d

# 4. VÃ©rifier les logs
docker-compose logs -f

# 5. AccÃ©der Ã  l'application
# Interface: http://localhost:5000
# API: http://localhost:5000/chat
```

### Option 3: Installation Locale (DÃ©veloppeurs)

Pour dÃ©veloppement et personnalisations avancÃ©es :

```bash
# 1. Cloner et prÃ©parer
git clone https://github.com/yassinebouachrine/hcp-chatbot.git
cd hcp-chatbot

# 2. Environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les donnÃ©es HCP
# S'assurer que data/indicators.json existe et contient les donnÃ©es

# 5. Lancer l'application
python app.py

# Application disponible sur http://localhost:5000
```

## ğŸ”§ Configuration AvancÃ©e

### Configuration AvancÃ©e ModÃ¨les

```env
# Configuration Flask
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=False

# Configuration ModÃ¨les IA
MODEL_PATH=models/models_hcp        # Chemin modÃ¨le fine-tunÃ©
BASE_MODEL=distilgpt2              # ModÃ¨le base Hugging Face
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2  # Embeddings

# Configuration GÃ©nÃ©ration
SIMILARITY_THRESHOLD=0.75          # Seuil de pertinence (0.0-1.0)
MAX_LENGTH=128                     # Longueur max des rÃ©ponses
TEMPERATURE=0.3                    # CrÃ©ativitÃ© des rÃ©ponses (0.1-1.0)
TOP_K=50                          # Top-K sampling
TOP_P=0.95                        # Nucleus sampling

# Configuration Performance  
BATCH_SIZE=64                     # Taille de batch (ajuster selon RAM)
EMBEDDING_BATCH_SIZE=32           # Batch pour embeddings
CACHE_EMBEDDINGS=True             # Cache des embeddings calculÃ©s

# Configuration HuggingFace
HUGGING_FACE_TOKEN=your_token_here # Token pour modÃ¨les privÃ©s

# Configuration GPU (si disponible)
USE_CUDA=False                    # True pour utiliser GPU
FP16=False                        # PrÃ©cision mixte pour GPU
DEVICE_MAP=auto                   # RÃ©partition automatique GPU

# Logging et Debug
LOG_LEVEL=INFO                    # DEBUG, INFO, WARNING, ERROR
SAVE_CONVERSATIONS=True           # Historique des conversations
```

### ğŸ›ï¸ Optimisation Performances

**Configuration par Type de Machine :**

#### Machine Standard (4-8GB RAM)
```env
# OptimisÃ© pour ressources limitÃ©es
BASE_MODEL=distilgpt2
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
BATCH_SIZE=16
EMBEDDING_BATCH_SIZE=8
MAX_LENGTH=96
USE_CUDA=False
FP16=False
CACHE_EMBEDDINGS=True
```

#### Machine Puissante (16GB+ RAM)
```env
# OptimisÃ© pour performance maximale
BASE_MODEL=distilgpt2
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
BATCH_SIZE=64
EMBEDDING_BATCH_SIZE=32
MAX_LENGTH=128
USE_CUDA=True  # Si GPU disponible
FP16=True
CACHE_EMBEDDINGS=True
```

#### Serveur Production (32GB+ RAM)
```env
# Configuration serveur haute charge
BASE_MODEL=distilgpt2
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
BATCH_SIZE=128
EMBEDDING_BATCH_SIZE=64
MAX_LENGTH=150
USE_CUDA=True
FP16=True
CACHE_EMBEDDINGS=True
WORKERS=4  # Processus Flask multiples
```

#### **Pourquoi ces ModÃ¨les ?**

| ModÃ¨le | Avantage | Taille | Performance |
|--------|----------|--------|-------------|
| **DistilGPT2** | 40% plus rapide que GPT2 | 82M params | GÃ©nÃ©ration fluide |
| **all-MiniLM-L6-v2** | Le plus rapide des SBERT | 22M params | 14K phrases/sec |

## ğŸ§ª Test et Validation

### Endpoints API Disponibles

| Endpoint | MÃ©thode | Description | Exemple |
|----------|---------|-------------|---------|
| `/` | GET | Interface web principale | - |
| `/health` | GET | Statut systÃ¨me | `{"status": "healthy"}` |
| `/chat` | POST | Chat avec IA | `{"message": "Population Casablanca"}` |
| `/territories` | GET | Liste territoires HCP | Tous les territoires disponibles |

### Exemples de Test API

```bash
# Test basique - Population nationale
curl -X POST http://localhost:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Quelle est la population du Maroc?"}'

# Test territorial - Ville spÃ©cifique  
curl -X POST http://localhost:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Population de Rabat"}'

# Test indicateur dÃ©mographique
curl -X POST http://localhost:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Pourcentage de femmes mariÃ©es au niveau national"}'

# Test Ã¢ge spÃ©cifique
curl -X POST http://localhost:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Population de 25-29 ans Ã  Casablanca"}'
```

### RÃ©ponse API Type

```json
{
  "response": "La population lÃ©gale du Maroc (Ensemble du territoire national) est de 33 848 242 habitants selon les derniÃ¨res donnÃ©es HCP.",
  "status": "success",
  "metadata": {
    "model_used": "semantic_search",
    "qa_pairs_count": 140567,
    "territory_detected": "Ensemble du territoire national",
    "indicator_detected": "population_legale",
    "confidence_score": 0.89,
    "response_time_ms": 245
  }
}
```

## ğŸ“Š DonnÃ©es SupportÃ©es

### Couverture GÃ©ographique

- **ğŸ›ï¸ Niveau National** : Ensemble du territoire
- **ğŸ—ºï¸ RÃ©gions** : 12 rÃ©gions administratives
- **ğŸ¢ Provinces** : 75+ provinces et prÃ©fectures  
- **ğŸ˜ï¸ Communes** : 1500+ communes urbaines et rurales
- **ğŸ“ Autres Territoires** : Arrondissements, districts

### Indicateurs DÃ©mographiques

| CatÃ©gorie | Indicateurs | Exemples |
|-----------|-------------|----------|
| **ğŸ‘¥ Population** | Population lÃ©gale/municipale | Total, par genre, par Ã¢ge |
| **ğŸ’’ Ã‰tat Matrimonial** | CÃ©libataires, mariÃ©s, divorcÃ©s, veufs | Par genre, par Ã¢ge |
| **ğŸ‚ Tranches d'Ã‚ge** | 0-4, 5-9, ..., 85+ | Population dÃ©taillÃ©e |
| **ğŸ’¼ Emploi** | Population active, chÃ´mage | Taux d'activitÃ© |
| **ğŸ“ Ã‰ducation** | Scolarisation, alphabÃ©tisation | Par niveau |
| **ğŸ  MÃ©nages** | Taille moyenne, composition | Structure familiale |

### Questions Types SupportÃ©es

- â“ **Population** : "Population de [Territoire]"
- â“ **Genre** : "Nombre de femmes Ã  [Lieu]"
- â“ **Ã‚ge** : "Population de 25-29 ans au Maroc"
- â“ **Matrimonial** : "Pourcentage de mariÃ©s Ã  [Ville]"
- â“ **Comparaison** : "DiffÃ©rence population entre Rabat et Casablanca"
- â“ **Ã‰volution** : "Ã‰volution population [RÃ©gion]"

## ğŸ” Monitoring et Maintenance

### Surveillance SystÃ¨me

```bash
# VÃ©rifier l'Ã©tat de santÃ©
curl http://localhost:5000/health

# Logs en temps rÃ©el
docker-compose logs -f hcp-chatbot

# Utilisation ressources
docker stats hcp-chatbot-app

# Informations dÃ©taillÃ©es
docker-compose exec hcp-chatbot htop
```

### Mise Ã  jour des DonnÃ©es

```bash
# Nouvelle version des donnÃ©es HCP
cp nouvelles_donnees.json data/indicators.json

# RedÃ©marrer pour appliquer
docker-compose restart hcp-chatbot

# VÃ©rifier le chargement
curl http://localhost:5000/health
```

## ğŸ›¡ï¸ Production et SÃ©curitÃ©

### DÃ©ploiement Production

```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  hcp-chatbot:
    image: bouachrineyassine/hcp-chatbot:latest
    restart: always
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=False
      - LOG_LEVEL=WARNING
    ports:
      - "80:5000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

### Configuration Reverse Proxy (Nginx)

```nginx
server {
    listen 80;
    server_name votre-domaine.com;
    
    location / {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

## ğŸ¤ Contribution et DÃ©veloppement

### Structure de DÃ©veloppement

```bash
# Fork du repository
git clone https://github.com/votre-username/hcp-chatbot.git

# Branche de dÃ©veloppement
git checkout -b feature/nouvelle-fonctionnalite

# Environnement de dev
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Outils de dev

# Tests
python -m pytest tests/

# Lancer en mode dÃ©veloppement
export FLASK_DEBUG=True
python app.py
```

### Roadmap Futur

- ğŸ”„ **API GraphQL** pour requÃªtes complexes
- ğŸ“± **Application Mobile** React Native
- ğŸ—£ï¸ **Support Vocal** avec reconnaissance/synthÃ¨se
- ğŸ“ˆ **Visualisations Interactives** avec charts dynamiques
- ğŸ” **Recherche AvancÃ©e** avec filtres multiples
- ğŸŒ **Multilingue Complet** (FranÃ§ais, Arabe, BerbÃ¨re)
- ğŸ”— **IntÃ©grations** avec autres sources officielles

## ğŸ“ Support et Contact

### Ressources Utiles

- ğŸ“– **Documentation** : Disponible dans `/docs`
- ğŸ› **Issues** : [GitHub Issues](https://github.com/yassinebouachrine/hcp-chatbot/issues)
- ğŸ’¬ **Discussions** : [GitHub Discussions](https://github.com/yassinebouachrine/hcp-chatbot/discussions)
- ğŸ“§ **Contact** : [yassine.bouachrine@example.com](mailto:yassine.bouachrine@example.com)

### Diagnostic Rapide

```bash
# VÃ©rification complÃ¨te des modÃ¨les
docker-compose exec hcp-chatbot python -c "
from src.chatbot import HCPChatbotAdapted
from config import Config
import torch
print('âœ… Modules OK')

# VÃ©rifier les modÃ¨les
print(f'ğŸ“Š ModÃ¨le base: {Config.BASE_MODEL}')
print(f'ğŸ” ModÃ¨le embeddings: {Config.EMBEDDING_MODEL}')
print(f'ğŸ’¾ Chemin modÃ¨les: {Config.MODEL_PATH}')
print(f'ğŸš€ CUDA disponible: {torch.cuda.is_available()}')

chatbot = HCPChatbotAdapted(Config)
print('âœ… Chatbot initialisÃ© avec DistilGPT2 + MiniLM')

response = chatbot.get_response('Population du Maroc')
print(f'âœ… Test rÃ©ponse: {response[:50]}...')
print(f'ğŸ“ˆ Embeddings chargÃ©s: {len(chatbot.embeddings) if hasattr(chatbot, \"embeddings\") else \"N/A\"}')
"
```

## ğŸ“œ Licence et Remerciements

### Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

### Remerciements

- ğŸ›ï¸ **Haut-Commissariat au Plan (HCP)** pour les donnÃ©es officielles
- ğŸ¤— **Hugging Face** pour les modÃ¨les de transformers
- ğŸ³ **Docker** pour la containerisation
- ğŸŒ¶ï¸ **Flask** pour le framework web
- ğŸ‘¥ **CommunautÃ© Open Source** pour les outils et bibliothÃ¨ques

---

<div align="center">

**ğŸ‡²ğŸ‡¦ Fait avec â¤ï¸ pour faciliter l'accÃ¨s aux donnÃ©es dÃ©mographiques du Maroc**

[â­ Star ce projet](https://github.com/yassinebouachrine/hcp-chatbot) â€¢ [ğŸ³ Docker Hub](https://hub.docker.com/r/bouachrineyassine/hcp-chatbot) â€¢ [ğŸ“Š DÃ©mo Live](http://votre-demo.com)

</div>
